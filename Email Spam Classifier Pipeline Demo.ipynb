{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read labeled email data\n",
    "1 = ham\n",
    "0 = spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|email_id|                text|label|\n",
      "+--------+--------------------+-----+\n",
      "|       1|One of a kind Mon...|    0|\n",
      "|      10|Re: What to choos...|    1|\n",
      "|     100|Strictly Private....|    0|\n",
      "|    1000|Re: Flash is open...|    1|\n",
      "|    1001|Re: Alsa/Redhat 8...|    1|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(\"train_parquet/\")\n",
    "data.cache()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 2500\n"
     ]
    }
   ],
   "source": [
    "print \"Training data: %d\" % data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Spark ML pipeline consisting of:\n",
    "1. **Tokenizer** - extract tokens from raw text\n",
    "2. **Count vectorizer** - convert tokens to term-frequency vectors\n",
    "3. **IDF** - normalize term-frequency vectors using TF-IDF\n",
    "4. **Logistic Regression** for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"[^a-zA-Z_0-9]+\")\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=30)\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use K-fold Cross Validation for Model Selection for Pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_eval = BinaryClassificationEvaluator()\n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [1e-3, 1e-2]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.25, 0.0]) \\\n",
    "    .addGrid(cv.vocabSize, [10000, 50000]) \\\n",
    "    .addGrid(idf.minDocFreq, [0, 3]) \\\n",
    "    .build()\n",
    "cross_val = CrossValidator(estimator=pipeline, evaluator=auc_eval, estimatorParamMaps=grid, numFolds=3)\n",
    "pipeline_model = cross_val.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "regParam: 0.001; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.994703388226\n",
      "regParam: 0.01; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.994337609943\n",
      "regParam: 0.01; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.994124213595\n",
      "regParam: 0.001; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.993912311874\n",
      "regParam: 0.001; elasticNet: 0.25, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.993836705568\n",
      "regParam: 0.001; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.993431752622\n",
      "regParam: 0.01; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.993430946302\n",
      "regParam: 0.01; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.993413552489\n",
      "regParam: 0.001; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.993098352005\n",
      "regParam: 0.001; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 3 - ROC score: 0.993038119979\n",
      "regParam: 0.01; elasticNet: 0.25, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.992917419546\n",
      "regParam: 0.01; elasticNet: 0.0, vocabSize: 10000, minDocFreq: 0 - ROC score: 0.992659851427\n",
      "regParam: 0.01; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.992046413018\n",
      "regParam: 0.001; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 3 - ROC score: 0.991710318067\n",
      "regParam: 0.01; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.989303264596\n",
      "regParam: 0.001; elasticNet: 0.0, vocabSize: 50000, minDocFreq: 0 - ROC score: 0.987625869713\n"
     ]
    }
   ],
   "source": [
    "scores = zip(grid, pipeline_model.avgMetrics)\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "print \"Cross-validation scores:\"\n",
    "for s in scores:\n",
    "    p = s[0]\n",
    "    print \"regParam: %s; elasticNet: %s, vocabSize: %s, minDocFreq: %s - ROC score: %s\" % \\\n",
    "        (p[lr.regParam], p[lr.elasticNetParam], p[cv.vocabSize], p[idf.minDocFreq], s[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Best PipelineModel to Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RegexTokenizer_422cb14cc91d8cb75da0, CountVectorizer_4609bd0606c0a106abc5, IDF_47339268d1d054dd59fd, LogisticRegression_4df9a2979bd5b2311e20]\n",
      "CrossValidatorModel_4ce8b81002e7a3303cd4\n",
      "PipelineModel_421f8a7fcb8a4ae48f3d\n"
     ]
    }
   ],
   "source": [
    "print pipeline.getStages()\n",
    "print pipeline_model\n",
    "print pipeline_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|email_id|                text|label|\n",
      "+--------+--------------------+-----+\n",
      "|       1|One of a kind Mon...|    0|\n",
      "|      10|Re: What to choos...|    1|\n",
      "|     100|Strictly Private....|    0|\n",
      "|    1000|Re: Flash is open...|    1|\n",
      "|    1001|Re: Alsa/Redhat 8...|    1|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|                text|               words|            features|label|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|One of a kind Mon...|[one, of, a, kind...|(50000,[0,1,2,3,4...|    0|       0.0|\n",
      "|Re: What to choos...|[re, what, to, ch...|(50000,[0,1,2,3,4...|    1|       1.0|\n",
      "|Strictly Private....|[strictly, privat...|(50000,[0,1,2,3,4...|    0|       0.0|\n",
      "|Re: Flash is open...|[re, flash, is, o...|(50000,[0,1,2,3,4...|    1|       1.0|\n",
      "|Re: Alsa/Redhat 8...|[re, alsa, redhat...|(50000,[0,1,2,3,4...|    1|       1.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example pipeline output\n",
    "data.show(5)\n",
    "pipeline_model.transform(data).select(\"text\", \"words\", \"features\", \"label\", \"prediction\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
